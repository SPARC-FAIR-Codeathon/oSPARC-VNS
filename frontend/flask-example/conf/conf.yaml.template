
# Intended to get written to /conf/base.yaml: 

control:
  ANN: u_net_modified
  Method: all_axons_segmentation
  data_set: {{name}}
  ground_truth: XML
  wrangled: # UPLOAD step
    enabled: false #  
    ground_truth: false
    image: false
    histogram_matching: false
  processed: # PRE-PROCESS step
    enabled: true
    ground_truth: false
    patching: false
  modelled: # RETRAIN step
    enabled: false
    generate_train_valid_dataset: false
    data_sets_to_use_in_modelling: {{name}}
    training: false
  model_evaluated: # SEGMENT step
    enabled: true
    model_version: {{version}} # << 5 ?
  post_processed: # ANNOTATE step
    enabled: true
    produce_xml: {{doXML}}
  reported: # I'm not 100% on what this step does
    enabled: true 
tuning:
  wrangled:
    parallel_processing: true
  processed:
    parallel_processing: true
    save_mask_separately_for_each_class: {{not doXML}}
    mask_colours:
      myelin: 127
      myelinated_axon: 255
      unmyelinated_axon: 170
    patching:
      patch_pixel_size: {{ model_p2um }} # 0.03 , needs to match trained model
      patch_size: {{ model_npx }} # 512, needs to match 
  modelled: # in this hypothetical example we aren't running this
    parallel_processing: true
    loss_type: dice_all_equal
    epochs: 10000
    visualize_activations: false
    save_augmentation_output: false
    random_seed: 2020
    train_set_size: 0.7
  model_evaluated:
    parallel_processing: true
    save_prediction_separately_for_each_class: false
    show_true_mask_overlay_on_prediction: false
    patch_pixel_size: sample
  post_processed:
    parallel_processing: true
  reported:
    parallel_processing: true
settings: # this is all for using the HPC to retrain the model, not relevent to this use case
  spartan:
    account: punim0123
    user_name: ''
    partition: gpgpu
    cpus_per_task: 24
    gpus_per_node: 4
    memory: 100000
    time:
      days: 5
      hours: 20
      minutes: 30
  data_sync: 
    from: mrc
    to: spartan
    folder_names: original